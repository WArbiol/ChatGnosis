# ü§ñ Chat Gnosis: Uma Aplica√ß√£o de RAG com LLMs na Nuvem

[![Python 3.9+](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.35-red.svg)](https://streamlit.io)
[![Google Gemini API](https://img.shields.io/badge/Google_Gemini-API-4285F4.svg)](https://ai.google.dev/)
[![Licen√ßa: MIT](https://img.shields.io/badge/Licen√ßa-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

- LLMs (Large Language Models)
- Busca Vetorial (Vector Search)
- Bancos de Dados Vetoriais (ChromaDB)
- Engenharia de Prompt (Prompt Engineering)
- Hugging Face Hub
- Deploy em Nuvem (Serverless)
- Streamlit

---

Uma aplica√ß√£o inteligente de Q&A que permite conversar com uma grande cole√ß√£o de documentos PDF, utilizando um pipeline de **Retrieval-Augmented Generation (RAG)** para fornecer respostas fi√©is, r√°pidas e com fontes citadas, com todo o processamento de IA executado na nuvem.

---

## üé• Demonstra√ß√£o

![Image](https://github.com/user-attachments/assets/1e5b1765-30c7-4cc4-8a5f-03a232c49b70)

&rarr; Acesse o site: [https://chatgnosis.streamlit.app/](https://chatgnosis.streamlit.app/)

---

## üí° Sobre o Projeto

Este projeto busca responder as perguntas do usu√°rio com base em um banco de dados alimentado por livros Gn√≥sticos. Foi arquitetado como uma aplica√ß√£o web completa, modular e pronta para deploy, demonstrando pr√°ticas modernas de engenharia de software para sistemas de IA. O objetivo √© criar uma ferramenta de pesquisa sem√¢ntica robusta, onde um usu√°rio pode fazer perguntas complexas em linguagem natural e receber respostas sintetizadas a partir de uma base de conhecimento privada.

A arquitetura foi cuidadosamente planejada para separar as responsabilidades, garantindo que a aplica√ß√£o seja escal√°vel, de f√°cil manuten√ß√£o e flex√≠vel.

## üöÄ Tecnologias e Arquitetura

A aplica√ß√£o √© constru√≠da sobre um stack tecnol√≥gico moderno e eficiente, otimizado para uma arquitetura "serverless" e escal√°vel.

### **Frontend**

- **Streamlit:** Utilizado para a cria√ß√£o de uma interface de usu√°rio reativa e interativa com c√≥digo Python puro, ideal para o desenvolvimento r√°pido de aplica√ß√µes de dados.

### **Backend & L√≥gica de IA (Pipeline RAG na Nuvem)**

O cora√ß√£o da aplica√ß√£o √© um pipeline de RAG que orquestra servi√ßos de IA na nuvem, tornando a aplica√ß√£o extremamente leve e eficiente.

#### 1. **Indexa√ß√£o (A Mem√≥ria da IA)**

Este processo offline transforma os documentos PDF em uma base de conhecimento vetorial.

- **Extra√ß√£o de Texto:** `PyMuPDF` foi escolhido por sua alta performance e efici√™ncia.
- **Fragmenta√ß√£o Sem√¢ntica:** `langchain-text-splitters` √© utilizado para quebrar os textos em "chunks" de forma inteligente, preservando o contexto.
- **Vetoriza√ß√£o (Embeddings via API):** A cria√ß√£o dos vetores sem√¢nticos √© feita atrav√©s de chamadas √† **API do Google Gemini (`text-embedding-004`)**. Isso garante embeddings de alt√≠ssima qualidade sem a necessidade de carregar modelos pesados localmente.
- **Banco de Dados Vetorial:** `ChromaDB` atua como nosso banco de dados vetorial local e persistente.

#### 2. **Recupera√ß√£o e Gera√ß√£o (O Racioc√≠nio da IA na Nuvem)**

Este processo online √© ativado a cada pergunta do usu√°rio.

- **Motor de Gera√ß√£o (LLM via API):** Toda a gera√ß√£o de texto √© realizada pela **API do Google Gemini (`gemini-1.5-flash`)**. A aplica√ß√£o envia o contexto recuperado e a pergunta do usu√°rio, recebendo uma resposta de alta qualidade gerada pela infraestrutura massiva do Google.
- **Prompt Engineering:** Uma estrat√©gia de prompt robusta √© utilizada para instruir o LLM a basear suas respostas estritamente no contexto recuperado, garantindo a fidelidade da informa√ß√£o.

## ‚ú® Funcionalidades

- [x] **Arquitetura Serverless:** Todo o processamento pesado de IA (embeddings e gera√ß√£o de texto) √© terceirizado para APIs de nuvem, resultando em uma aplica√ß√£o leve e com baixo consumo de recursos.
- [x] **Interface Reativa e Moderna:** Tema escuro customiz√°vel com CSS.
- [x] **Chat em Tempo Real:** Respostas geradas por streaming diretamente da API, com efeito de "digita√ß√£o".
- [x] **Fidelidade e Cita√ß√£o de Fontes:** A IA exibe os trechos exatos dos documentos originais que usou para formular a resposta.
- [x] **Pipeline de Ingest√£o Desacoplado:** Um script dedicado para processar e indexar os documentos, separando o "modo admin" do "modo usu√°rio".
- [x] **Pronto para Deploy:** A aplica√ß√£o foi projetada e implementada para deploy na nuvem, com gerenciamento de segredos e artefatos de dados.

## üîß Instala√ß√£o e Execu√ß√£o

Para executar este projeto localmente, siga os passos abaixo:

**1. Pr√©-requisitos:**

- Python 3.9 ou superior
- Git

**2. Clone o Reposit√≥rio:**

```bash
git clone [https://github.com/WArbiol/ChatGnosis.git](https://github.com/WArbiol/ChatGnosis.git)
cd ChatGnosis
```

**3. Crie e Ative um Ambiente Virtual:**

```bash
python -m venv venv
source venv/bin/activate  # No macOS/Linux
# ou
.\venv\Scripts\activate  # No Windows
```

**4. Instale as Depend√™ncias:**

```bash
pip install -r requirements.txt
```

**5. Configure suas Chaves de API:**

- Crie o arquivo `.streamlit/secrets.toml` e adicione sua chave da API do Google Gemini:
  ```toml
  GOOGLE_API_KEY = "SUA_CHAVE_API_AQUI"
  ```

**6. Prepare a Base de Conhecimento:**

- Coloque seus arquivos PDF na pasta `data/pdfs/`.
- Execute o script de ingest√£o uma √∫nica vez (requer a chave de API configurada):
  ```bash
  python scripts/build_vector_store.py
  ```

**7. Execute a Aplica√ß√£o:**

- Inicie a aplica√ß√£o Streamlit:
  ```bash
  streamlit run app.py
  ```

## ‚òÅÔ∏è Arquitetura de Deploy

Esta aplica√ß√£o foi implantada usando um padr√£o "serverless" moderno e eficiente:

- **Frontend:** Implantado gratuitamente no **Streamlit Community Cloud**.
- **Base de Conhecimento:** A pasta `vector_store` gerada √© hospedada como um "dataset" no **Hugging Face Hub**, mantendo o reposit√≥rio Git leve e desacoplado dos dados.
- **LLM Backend:** Toda a l√≥gica de IA √© gerenciada pela **API do Google Gemini**, permitindo um deploy de baixo custo (dentro do n√≠vel gratuito) e alt√≠ssima escalabilidade, sem a necessidade de gerenciar servidores de GPU.

## üë®‚Äçüíª Autor

**Walter Melhado Arbiol Forn√©**

- **LinkedIn:** [linkedin.com/in/walter-melhado-arbiol-forne-818656211/](https://www.linkedin.com/in/walter-melhado-arbiol-forne-818656211/)
- **GitHub:** [github.com/WArbiol](https://github.com/WArbiol)
- **Email:** [walterarbiol@gmail.com](mailto:walterarbiol@gmail.com)

## üìú Licen√ßa

Distribu√≠do sob a licen√ßa MIT. Veja `LICENSE` para mais informa√ß√µes.
